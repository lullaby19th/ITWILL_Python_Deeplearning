{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cafe.daum.net/oracleoracle/ScIc/240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제79. 구구단 2단에서 ~ 9단까지 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_dict 기능 숙지하기.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(0) # x 변수 선언하면서 0을 할당\n",
    "y = tf.Variable(0) # y 변수 선언하면서 0을 할당\n",
    "z = tf.multiply(x,y) # x와 y를 곱한 값이 z에 할당되게 한다.\n",
    "\n",
    "init = tf.global_variables_initializer() #위에서 변수를 생성했으면 반드시\n",
    "                                         # 변수를 초기화 해주어야한다.\n",
    "sess = tf.Session() # 텐서플로우 그래프를 실행할 세션을 sess로 선언한다.\n",
    "sess.run(init) # init 변수를 실행한다.\n",
    "\n",
    "for i in range(2,10):\n",
    "    for j in range(1,10):\n",
    "        print(i, 'x', j, '=', sess.run(z, feed_dict = {x:i, y:j}))\n",
    "        # feed_dict 명령어로 데이터를 텐서 그래프에 주입한다.\n",
    "        # x변수에는 i의 값을 대입하고 y변수에는 j값을 대입한다.\n",
    "        # z를 실행하기 위해서 x와 y에 값을 대입한다.\n",
    "        \n",
    "sess.close() # sess.close()로 마무리하는걸 잊지 말자. or with절로 시작하면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 신경망에서 bias를 만드는 코드를 텐서 플로우로 구현하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제1. 변수에 숫자 0과 숫자 1을 채워넣는 배열을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# numpy로 구현\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.zeros((2,2))\n",
    "b = np.ones((2,2))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 로 구현하는 방법\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.zeros((2,2))\n",
    "b = tf.ones((2,2))  # 그래프 그리는 영역\n",
    "init = tf.global_variables_initializer()\n",
    "#------------------------------------------\n",
    "                    # 그래프 실행하는 영역\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 배열의 원소중에서 최대값 원소의 인덱스를 찾는 코드\n",
    "\n",
    "1. 파이썬의 numpy를 이용하는 방법\n",
    "2. tensorflow를 이용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 1. 파이썬의 numpy를 이용하는 방법\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "print(np.argmax(a, axis = 0)) # 0은 열, 1은 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. tensorflow를 이용하는 방법\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "b = tf.argmax(a, axis=0)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(b))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 다차원 배열에서 행의 토탈값을 구하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  8 12]\n",
      " [10  8 11]\n",
      " [11  5 12]\n",
      " [13 15  6]]\n"
     ]
    }
   ],
   "source": [
    "# numpy 로 구현\n",
    "import  numpy  as  np\n",
    "\n",
    "a = np.array([[[1, 2, 3],\n",
    "\n",
    "               [2, 1, 4],\n",
    "\n",
    "               [5, 2, 1],\n",
    "\n",
    "               [6, 3, 2]],\n",
    "\n",
    "              [[5, 1, 3],\n",
    "\n",
    "               [1, 3, 4],\n",
    "\n",
    "               [4, 2, 6],\n",
    "\n",
    "               [3, 9, 3]],\n",
    "\n",
    "              [[4, 5, 6],\n",
    "\n",
    "               [7, 4, 3],\n",
    "\n",
    "               [2, 1, 5],\n",
    "\n",
    "               [4, 3, 1]]])\n",
    "\n",
    "print (np.sum(a, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. tensorflow로 구현\n",
    "import  tensorflow  as  tf\n",
    "import  numpy  as  np\n",
    "\n",
    "a = np.array([[[1, 2, 3],\n",
    "\n",
    "               [2, 1, 4],\n",
    "\n",
    "               [5, 2, 1],\n",
    "\n",
    "               [6, 3, 2]],\n",
    "\n",
    "              [[5, 1, 3],\n",
    "\n",
    "               [1, 3, 4],\n",
    "\n",
    "               [4, 2, 6],\n",
    "\n",
    "               [3, 9, 3]],\n",
    "\n",
    "              [[4, 5, 6],\n",
    "\n",
    "               [7, 4, 3],\n",
    "\n",
    "               [2, 1, 5],\n",
    "\n",
    "               [4, 3, 1]]])\n",
    "    \n",
    "d = tf.reduce_sum(a, reduction_indices=[0])\n",
    "sess = tf.Session()\n",
    "print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 텐서 플로우로 행렬 내적하는 코드\n",
    "\n",
    "1. numpy 형식\n",
    "2. tensorflow 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 18]\n",
      " [18 18]]\n"
     ]
    }
   ],
   "source": [
    "# 1. numpy 형식\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[2,2,2],[2,2,2]])\n",
    "b = np.array([[3,3],[3,3],[3,3]])\n",
    "\n",
    "result = np.dot(a,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. tensorflow 형식\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(\"float\", [2,3]) # 2x3 행렬의 실수형 데이터를 담을 변수\n",
    "y = tf.placeholder(\"float\", [3,2]) # 3x2 행렬의 실수형 데이터를 담을 변수\n",
    "\n",
    "result = tf.matmul(x,y) # matmul이 내적임.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(result, feed_dict = {x: [[2,2,2],[2,2,2]], \\\n",
    "                                        y : [[3,3],[3,3],[3,3]]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 문제80. (점심시간 문제) 아래의 행렬을 tensorflow로 내적하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(\"float\", [3,3]) # 2x3 행렬의 실수형 데이터를 담을 변수\n",
    "y = tf.placeholder(\"float\", [3,3]) # 3x2 행렬의 실수형 데이터를 담을 변수\n",
    "\n",
    "result = tf.matmul(x,y) # matmul이 내적임.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(result, feed_dict = {x: [[6,3,2],[7,5,4], [8,9,10]], \\\n",
    "                                        y : [[3,4,6],[5,9,7],[6,7,4]]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 신경망에서 정확도를 출력하는 코드\n",
    "\n",
    "\" tensorflow의 cast 함수의 이해 \" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 예제 : 아래의 배열의 True를 1로 변경하고 False를 0으로 변경시키시오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "correct_prediction = [ True, False , True  ,True  ,True  ,True  ,True,  True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True, False , True  ,True, False , True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True,\n",
    "\n",
    "  True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True ,False , True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True, False , True, False , True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    " ,False , True  ,True  ,True]\n",
    "\n",
    "sess = tf.Session()\n",
    "a = tf.cast(correct_prediction, \"float\") # tf.cast : True는 1로 False는 0으로 바꾸는 함수\n",
    "print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제81. 위의 출력된 결과에서 전체 갯수중에 1이 몇개나 되는지 정확도가 아래와 같이 출력되게 하시오!\n",
    "\n",
    "결과 : 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "correct_prediction = [ True, False , True  ,True  ,True  ,True  ,True,  True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True, False , True  ,True, False , True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True,\n",
    "\n",
    "  True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True ,False , True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True, False , True, False , True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    "  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True  ,True\n",
    "\n",
    " ,False , True  ,True  ,True]\n",
    "\n",
    "sess = tf.Session()\n",
    "a = tf.cast(correct_prediction, \"float\")\n",
    "b = tf.reduce_mean(a)\n",
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 텐서 플로우에서 mnist 데이터 가져오기\n",
    "\n",
    "\" 텐서플로우는 기본적으로 실습용으로 mnist 데이터가 내장되어 있다. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "print(batch_xs.shape) # (100, 784)\n",
    "print(batch_ys.shape) # (100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제82. mnist데이터에서 test 데이터 100개를 불러오시오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "batch_xs, batch_ys = mnist.test.next_batch(100) # test라 테스트 데이터\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "print(batch_xs.shape) # (100, 784)\n",
    "print(batch_ys.shape) # (100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 텐서 플로우에서 배치 단위로 데이터를 불러올때 None의 의미는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제1. 아래의 숫자 2로 채워진 행렬 2x3행렬을 텐서플로우로 구성하시오\n",
    "\n",
    "2 2 2   \n",
    "2 2 2  \n",
    "2 2 2   \n",
    "  .\n",
    "  .\n",
    "  \n",
    "#### ※ None으로 작성하게 되면 입력되는 행수가 몇개가 들어오던 관계 없다는 뜻이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(\"float\", [2,3]) # 2x3 행렬을 담을 변수를 생성\n",
    "sess = tf.Session()\n",
    "print(sess.run(x, feed_dict = {x:[[2,2,2],[2,2,2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제2. 위의 코드에서 [2,3] ---> [None,3]으로 변경해서 실행하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(\"float\", [None,3]) # None으로 인해 행은 아무행이더라도 가능해진다.\n",
    "sess = tf.Session()\n",
    "print(sess.run(x, feed_dict = {x:[[2,2,2],[2,2,2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제83. mnist 데이터 784(28x28) 개에 맞게 x 변수를 placeholder로 선언하고 배치로 입력될 데이터의 갯수는 몇개이든 관계없이 None을 사용한 변수를 만들고 Mnist 데이터를 x변수에 100개를 담고 출력해보시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(x, feed_dict = {x:batch_xs}).shape) # (100, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 텐서 플로우로 신경망을 만들때 가중치를 생성하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "# -1 ~ 1 사이의 숫자로 784 x 50 행렬의 변수를 W1로 생성한다.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(W1).shape) # (784,50)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Mnist 훈련데이터 100개와 785x50의 가중치와 내적한 결과의 shape를 출력하시오!\n",
    "\n",
    "100 x784 ◎ 784 x 50 = 100 x 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "y = tf.matmul(x, W1)\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y, feed_dict={x: batch_xs}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 1x50 으로 bias를 생성하는데 변수를 b로 해서 생성하고 숫자 1로 다채우는방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "b = tf.Variable(tf.ones([50]))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(b))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 문제84. mnist 훈련데이터 100개와 785x50의 가중치와 내적한 결과와 bias의 합을 구현하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b = tf.Variable(tf.ones([50]))\n",
    "y = tf.matmul(x, W1) +b\n",
    "\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y, feed_dict = { x: batch_xs}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제85. 위의 내적한 결과 y를 시그모이드 함수를 통과시켜서 y_hat으로 출력되게 하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b = tf.Variable(tf.ones([50]))\n",
    "y = tf.matmul(x, W1) +b\n",
    "y_hat = tf.nn.sigmoid(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y_hat, feed_dict = { x: batch_xs }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제86. 위의 활성화 함수를 sigmoid에서 relu로 변경하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b = tf.Variable(tf.ones([50]))\n",
    "y = tf.matmul(x, W1) +b\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y_hat, feed_dict = { x: batch_xs }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제87. 위의 1층 신경망을 통과한 y_hat과 50x10 행렬인 W2와 내적한 결과에 1x10으로 만든 b2의 합을 z로 출력되겠끔 코드를 추가하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(z, feed_dict = { x: batch_xs }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제88. 위에 2층에서 나온 z 값을 softmax 함수를 통과시켜 나온 z_hat으로 구현하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(z_hat, feed_dict = { x: batch_xs }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제89. 위의 출력된 확률백터에서 인덱스 번호를 출력하시오! (100개가 출력이 됨.)\n",
    "## tf.argmax를 사용하고 y_predict에 담으시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y_predict, feed_dict = { x: batch_xs }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제90. 위의 코드에 라벨(정답)을 가져오는 코드를 추가해서 정확도를 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아직 학습은 안함.\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(accuracy, feed_dict = { x: batch_xs, y_onehot : batch_ys }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 텐서플로우 신경망 학습 시키는 코드\n",
    "\n",
    "__\" 학습을 시키기 위해서 필요한 함수 \"__\n",
    "\n",
    "1. 오차함수\n",
    "    - 평균 제곱오차 : 회귀분석  \n",
    "        예 : loss = tf.square(y_predict, y_label)\n",
    "        \n",
    "        \n",
    "    - 교차 엔트로피 : 분류문제(p.115 참고)  \n",
    "        예 : loss = -tf.reduce_sum(y_onehot * tf.log(y_hat), axis = 1)     ## y_onehot = t(target)\n",
    "\n",
    "\n",
    "2. 경사감소법 함수\n",
    "    - SGD\n",
    "    - Momentum\n",
    "    - Adagrade\n",
    "    - Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ 경사감소법을 텐써 플로우로 구현하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD : \n",
    "\n",
    " 미니배치만큼 랜덤으로 데이터를 추출해서 확률적으로 경사를 감소 하여 global minima 로 찾아가는 방법 \n",
    "\n",
    "\n",
    "\n",
    "단점 :  Local minima 에 잘 빠진다. \n",
    "\n",
    "#### optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "\n",
    "## Adagrade:\n",
    "\n",
    "러닝 레이트가 학습되면서 자동 조절되는 경사감소법 \n",
    "\n",
    "#### optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)\n",
    "\n",
    "\n",
    "\n",
    "## Momentum\n",
    "\n",
    "관성을 이용해서 local minima 에 안빠지게 하는 경사감소법 \n",
    "\n",
    "#### optimizer = tf.train.MomentumOptimizer(learning_rate=0.01)\n",
    "\n",
    "\n",
    "## Adam\n",
    "\n",
    "Adagrade 의 장점 + Momentum 의 장점 \n",
    "#### optimizer = tf.train.AdamOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제91. 지금까지의 텐서플로우 신경망 코드에 오차함수인 교차엔트로피 함수를 추가하고 loss를 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(loss, feed_dict = { x: batch_xs, y_onehot : batch_ys }))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제92. 지금까지 만든 코드에 Adam 경사 감소법 코드를 추가해서 학습이 되게 하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 학습 시키는 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(loss, feed_dict = { x: batch_xs, y_onehot : batch_ys }))\n",
    "\n",
    "sess.run(train, feed_dict = { x: batch_xs, y_onehot : batch_ys }))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제93. 위의 오차가 100개 나오지 말고 100개의 평균값으로 출력되게하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "result = tf.reduce_mean(loss)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 학습 시키는 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(result, feed_dict = { x: batch_xs, y_onehot : batch_ys }))\n",
    "\n",
    "sess.run(train, feed_dict = { x: batch_xs, y_onehot : batch_ys })\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제94. 위의 결과를 오차가 아니라 정확도가 출력되게 코드를 수정하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "result = tf.reduce_mean(loss)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 학습 시키는 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "# batch_xs -> 훈련데이터\n",
    "# batch_ys -> 훈련데이터 라벨\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(accuracy, feed_dict = { x: batch_xs, y_onehot : batch_ys })) # accuracy로 바꿈\n",
    "\n",
    "sess.run(train, feed_dict = { x: batch_xs, y_onehot : batch_ys })\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제95. 위의 코드에 for loop문을 추가해서 1에폭 돌게 하시오!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "result = tf.reduce_mean(loss)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 학습 시키는 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer() # 변수 초기화는 딱 1번만 하면됨.\n",
    "\n",
    "# 세션 생성\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "for i in range(1,601): # 1epoch = 600번\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # batch_xs -> 훈련데이터\n",
    "    # batch_ys -> 훈련데이터 라벨\n",
    "    sess.run(train, feed_dict = { x: batch_xs, y_onehot : batch_ys })\n",
    "    print(sess.run(accuracy, feed_dict = { x: batch_xs, y_onehot : batch_ys })) # 정확도 출력을 위해 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제96. 위의 코드를 20에폭 돌리시오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# 1층\n",
    "x = tf.placeholder(\"float\", [None,784])\n",
    "W1 = tf.Variable(tf.random_uniform([784,50],-1,1))\n",
    "b1 = tf.Variable(tf.ones([50]))\n",
    "\n",
    "y = tf.matmul(x, W1) + b1\n",
    "y_hat = tf.nn.relu(y) # tensorflow에서는 sigmoid함수를 안만들어도 이렇게 하면 된다.\n",
    "\n",
    "# 2층 출력층\n",
    "W2 = tf.Variable(tf.random_uniform([50,10],-1,1))\n",
    "b2 = tf.Variable(tf.ones([10]))\n",
    "z = tf.matmul(y_hat, W2) + b2\n",
    "z_hat = tf.nn.softmax(z)\n",
    "y_predict = tf.argmax(z_hat, axis=1)\n",
    "\n",
    "# 정확도 확인\n",
    "y_onehot = tf.placeholder(\"float\", [None,10])\n",
    "y_label = tf.argmax(y_onehot, axis =1)\n",
    "\n",
    "correction_prediction = tf.equal(y_predict, y_label) # 같으면 True, 다르면 False\n",
    "accuracy = tf.reduce_mean(tf.cast(correction_prediction, \"float\")) # True = 1, False = 0 으로 바꿈\n",
    "\n",
    "# 오차 확인\n",
    "loss = -tf.reduce_sum(y_onehot * tf.log(z_hat), axis = 1)\n",
    "result = tf.reduce_mean(loss)\n",
    "# softmax를 통과한것을 tf.log부분에 넣어야 되기 때문에 z_hat이 들어간다.\n",
    "\n",
    "# 학습 시키는 코드\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer() # 변수 초기화는 딱 1번만 하면됨.\n",
    "\n",
    "# 세션 생성\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 데이터 불러오는 부분\n",
    "for i in range(1,601): # 1epoch = 600번\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # batch_xs -> 훈련데이터\n",
    "    # batch_ys -> 훈련데이터 라벨\n",
    "    sess.run(train, feed_dict = { x: batch_xs, y_onehot : batch_ys })\n",
    "    print(sess.run(accuracy, feed_dict = { x: batch_xs, y_onehot : batch_ys })) # 정확도 출력을 위해 accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
